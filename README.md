# awesome-ai-mental-health
**contents**

- [Theoretical basis ](#theoretical-basis )
- [Technological development ](#technological-development )
- [Clinical application](#clinical-application)

## Theoretical basis 

Hua, Y., Na, H., Li, Z., Liu, F., Fang, X., Clifton, D., & Torous, J. (2025). A scoping review of large language models for generative tasks in mental health care. *npj Digital Medicine*, *8*(1), 230.[[PDF](https://www.nature.com/articles/s41746-025-01611-4.pdf)]

Na, H., Hua, Y., Wang, Z., Shen, T., Yu, B., Wang, L., ... & Chen, L. (2025). A survey of large language models in psychotherapy: Current landscape and future directions. *arXiv preprint arXiv:2502.11095*.[[PDF](https://arxiv.org/pdf/2502.11095)]

Coda-Forno, J., Binz, M., Wang, J. X., & Schulz, E. (2024). Cogbench: a large language model walks into a psychology lab. *arXiv preprint arXiv:2402.18225*.[[PDF](https://openreview.net/pdf?id=Q3104y8djk)]

Lee, Seungbeen, et al. "Do llms have distinct and consistent personality? trait: Personality testset designed for llms with psychometrics." *arXiv preprint arXiv:2406.14703* (2024).[[PDF](https://arxiv.org/pdf/2406.14703)]

Li, X., Li, Y., Qiu, L., Joty, S., & Bing, L. (2022). Evaluating psychological safety of large language models. *arXiv preprint arXiv:2212.10529*.[[PDF](https://arxiv.org/pdf/2212.10529)]

Liu, T., Giorgi, S., Aich, A., Lahnala, A., Curtis, B., Ungar, L., & Sedoc, J. (2025). The Illusion of Empathy: How AI Chatbots Shape Conversation Perception. *Proceedings of the AAAI Conference on Artificial Intelligence*, *39*(13), 14327-14335. [[PDF](https://doi.org/10.1609/aaai.v39i13.33569)]

Zhou, P., Madaan, A., Potharaju, S. P., Gupta, A., McKee, K. R., Holtzman, A., ... & Faruqui, M. (2023). How far are large language models from agents with theory-of-mind?. *arXiv preprint arXiv:2310.03051*.[[PDF](https://arxiv.org/pdf/2310.03051)]

Huang, J. T., Wang, W., Li, E. J., Lam, M. H., Ren, S., Yuan, Y., ... & Lyu, M. (2023). On the humanity of conversational ai: Evaluating the psychological portrayal of llms. In *The Twelfth International Conference on Learning Representations*.[[PDF](https://openreview.net/pdf?id=H3UayAQWoE)]

Huang, J. T., Jiao, W., Lam, M. H., Li, E. J., Wang, W., & Lyu, M. (2024, November). On the reliability of psychological scales on large language models. In *Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing* (pp. 6152-6173).[[PDF](https://aclanthology.org/2024.emnlp-main.354.pdf)]

Bouguettaya, A., Stuart, E. M., & Aboujaoude, E. (2025). Racial bias in AI-mediated psychiatric diagnosis and treatment: a qualitative comparison of four large language models. *npj Digital Medicine*, *8*(1), 332.[[PDF](https://www.nature.com/articles/s41746-025-01746-4.pdf)]

Li, C., Wang, J., Zhang, Y., Zhu, K., Wang, X., Hou, W., ... & Xie, X. (2023). The good, the bad, and why: Unveiling emotions in generative ai. *arXiv preprint arXiv:2312.11111*.[[PDF](https://openreview.net/pdf?id=wlOaG9g0uq)]

Choi, S., Lee, J., Yi, X., Yao, J., Xie, X., & Bak, J. (2025). Unintended Harms of Value-Aligned LLMs: Psychological and Empirical Insights. *arXiv preprint arXiv:2506.06404*.[[PDF](https://aclanthology.org/2025.acl-long.1532.pdf)]

Thirunavukarasu, A. J., & O’Logbon, J. (2024). The potential and perils of generative artificial intelligence in psychiatry and psychology. *Nature Mental Health*, *2*(7), 745-746.[[PDF](https://www.nature.com/articles/s44220-024-00257-7.pdf)]

Demszky, D., Yang, D., Yeager, D. S., Bryan, C. J., Clapper, M., Chandhok, S., ... & Pennebaker, J. W. (2023). Using large language models in psychology. *Nature Reviews Psychology*, *2*(11), 688-701.[[PDF](https://www.nature.com/articles/s44159-023-00241-5.pdf)]

## Technological development

Varadarajan, V., Sikström, S., Kjell, O. N., & Schwartz, H. A. (2024, June). ALBA: Adaptive Language-Based Assessments for Mental Health. In *Proceedings of the conference. Association for Computational Linguistics. North American Chapter. Meeting* (Vol. 2024, p. 2466).[[PDF](https://aclanthology.org/2024.naacl-long.136.pdf)]

Garg, M., Shahbandegan, A., Chadha, A., & Mago, V. (2023). An annotated dataset for explainable interpersonal risk factors of mental disturbance in social media posts. *arXiv preprint arXiv:2305.18727*.[[PDF](https://arxiv.org/pdf/2305.18727)]

Huang, J. T., Lam, M. H., Li, E. J., Ren, S., Wang, W., Jiao, W., ... & Lyu, M. R. (2024). Apathetic or empathetic? evaluating llms' emotional alignments with humans. *Advances in Neural Information Processing Systems*, *37*, 97053-97087.[[PDF](https://papers.nips.cc/paper_files/paper/2024/file/b0049c3f9c53fb06f674ae66c2cf2376-Paper-Conference.pdf)]

Ravenda, F., Bahrainian, S. A., Raballo, A., Mira, A., & Kando, N. (2025). Are llms effective psychological assessors? leveraging adaptive rag for interpretable mental health screening through psychometric practice. *arXiv preprint arXiv:2501.00982*.[[PDF](https://arxiv.org/pdf/2501.00982)]

Xiao, M., Ye, M., Liu, B., Zong, X., Li, H., Huang, J., ... & Peng, M. (2025). A Retrieval-Augmented Multi-Agent Framework for Psychiatry Diagnosis. *arXiv preprint arXiv:2506.03750*.[[PDF](https://arxiv.org/pdf/2506.03750)]

Reuben, M., Slobodin, O., Elyshar, A., Cohen, I. C., Braun-Lewensohn, O., Cohen, O., & Puzis, R. (2024). Assessment and manipulation of latent constructs in pre-trained language models using psychometric scales. *arXiv preprint arXiv:2409.19655*.[[PDF](https://arxiv.org/pdf/2409.19655)]

Ben-Zion, Z., Witte, K., Jagadish, A. K., Duek, O., Harpaz-Rotem, I., Khorsandian, M. C., ... & Spiller, T. R. (2025). Assessing and alleviating state anxiety in large language models. *npj Digital Medicine*, *8*(1), 132.[[PDF](https://www.nature.com/articles/s41746-025-01512-6.pdf)]

Wang, B., Deng, P., Zhao, Y., & Qin, B. (2023, December). C2D2 dataset: A resource for the cognitive distortion analysis and its impact on mental health. In *Findings of the Association for Computational Linguistics: EMNLP 2023* (pp. 10149-10160).[[PDF](https://aclanthology.org/2023.findings-emnlp.680.pdf)]

Gabriel, Saadia, et al. "Can AI relate: Testing large language model response for mental health support." *arXiv preprint arXiv:2405.12021* (2024).[[PDF](https://arxiv.org/pdf/2405.12021)]

Lee, S., Kim, S., Kim, M., Kang, D., Yang, D., Kim, H., ... & Yeo, J. (2024). Cactus: Towards psychological counseling conversations using cognitive behavioral theory. *arXiv preprint arXiv:2407.03103*.[[PDF](https://arxiv.org/pdf/2407.03103?)]

Na, H. (2024). CBT-LLM: A Chinese large language model for cognitive behavioral therapy-based mental health question answering. *arXiv preprint arXiv:2403.16008*.[[PDF](https://arxiv.org/pdf/2403.16008)]

Zhai, W., Qi, H., Zhao, Q., Li, J., Wang, Z., Wang, H., ... & Fu, G. (2024). Chinese MentalBERT: Domain-adaptive pre-training on social media for Chinese mental health text analysis. *arXiv preprint arXiv:2402.09151*.[[PDF](https://aclanthology.org/2024.findings-acl.629.pdf)]

Kallstenius, T., Capusan, A. J., Andersson, G., & Williamson, A. (2025). Comparing traditional natural language processing and large language models for mental health status classification: a multi-model evaluation. *Scientific Reports*, *15*(1), 1-13.[[PDF](https://www.nature.com/articles/s41598-025-08031-0.pdf)]

Zhao, J., Zhu, J., Tan, M., Yang, M., Li, R., Yang, D., ... & Wong, D. F. (2024). CPsyExam: A Chinese Benchmark for Evaluating Psychology using Examinations. *arXiv preprint arXiv:2405.10212*.[[PDF](https://arxiv.org/pdf/2405.10212?)]

Zhang, C., Li, R., Tan, M., Yang, M., Zhu, J., Yang, D., ... & Hu, X. (2024). Cpsycoun: A report-based multi-turn dialogue reconstruction and evaluation framework for chinese psychological counseling. *arXiv preprint arXiv:2405.16433*.[[PDF](https://arxiv.org/pdf/2405.16433?)]

Kang, M., Choi, G., Jeon, H., An, J. H., Choi, D., & Han, J. (2024, November). CURE: Context-and uncertainty-aware mental disorder detection. In *Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing* (pp. 17924-17940).[[PDF](https://aclanthology.org/2024.emnlp-main.994.pdf)]

Ma, J., Na, H., Wang, Z., Hua, Y., Liu, Y., Wang, W., & Chen, L. (2024). Detecting conversational mental manipulation with intent-aware prompting. *arXiv preprint arXiv:2412.08414*.[[PDF](https://arxiv.org/pdf/2412.08414?)]

Aragón, M. E., López-Monroy, A. P., González, L. C., Losada, D. E., & Montes, M. (2023, July). DisorBERT: A double domain adaptation model for detecting signs of mental disorders in social media. In *Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)* (pp. 15305-15318).[[PDF](https://aclanthology.org/2023.acl-long.853.pdf)]

Nguyen, V. C., Taher, M., Hong, D., Possobom, V. K., Gopalakrishnan, V. T., Raj, E., ... & De Choudhury, M. (2024). Do large language models align with core mental health counseling competencies?. *arXiv preprint arXiv:2410.22446*.[[PDF](https://arxiv.org/pdf/2410.22446)]

Zhou, Y., Zhou, N., Chen, Q., Zhou, J., Zhou, A., & He, L. (2025). DiaCBT: A Long-Periodic Dialogue Corpus Guided by Cognitive Conceptualization Diagram for CBT-based Psychological Counseling. *arXiv preprint arXiv:2509.02999*[[PDF](https://arxiv.org/pdf/2509.02999?)]

Sun, X., Pei, J., de Wit, J., Aliannejadi, M., Krahmer, E., Dobber, J. T., & Bosch, J. A. (2024, May). Eliciting motivational interviewing skill codes in psychotherapy with LLMs: A bilingual dataset and analytical study. In *Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)* (pp. 5609-5621).[[PDF](https://aclanthology.org/2024.lrec-main.498.pdf)]
Atapattu, T., Herath, M., Elvitigala, C., de Zoysa, P., Gunawardana, K., Thilakaratne, M., ... & Falkner, K. (2022). Emoment: An emotion annotated mental health corpus from two south asian countries. *arXiv preprint arXiv:2208.08486*.[[PDF](https://arxiv.org/pdf/2208.08486)]

Chen, Y., Wang, H., Yan, S., Liu, S., Li, Y., Zhao, Y., & Xiao, Y. (2024). Emotionqueen: A benchmark for evaluating empathy of large language models. *arXiv preprint arXiv:2409.13359*.[[PDF](https://arxiv.org/pdf/2409.13359)]

Chen, Z., Lu, Y., & Wang, W. Y. (2023). Empowering psychotherapy with large language models: Cognitive distortion detection through diagnosis of thought prompting. *arXiv preprint arXiv:2310.07146*.[[PDF](https://arxiv.org/pdf/2310.07146)]

Zhao, H., Li, L., Chen, S., Kong, S., Wang, J., Huang, K., ... & Wang, Y. (2024). ESC-Eval: Evaluating emotion support conversations in large language models. *arXiv preprint arXiv:2406.14952*.[[PDF](https://arxiv.org/pdf/2406.14952)]

Maurya, R., Rajput, N., Diviit, M. G., Mahapatra, S., & Ojha, M. K. (2025). Exploring the potential of lightweight large language models for AI-based mental health counselling task: a novel comparative study. *Scientific Reports*, *15*(1), 22463.[[PDF](https://www.nature.com/articles/s41598-025-05012-1.pdf)]

Xiao, M., Xie, Q., Kuang, Z., Liu, Z., Yang, K., Peng, M., ... & Huang, J. (2024). Healme: Harnessing cognitive reframing in large language models for psychotherapy. *arXiv preprint arXiv:2403.05574*.[[PDF](https://arxiv.org/pdf/2403.05574)]

Kim, H., Lee, S., Cho, Y., Ryu, E., Jo, Y., Seong, S., & Cho, S. (2025). KMI: A Dataset of Korean Motivational Interviewing Dialogues for Psychotherapy. *arXiv preprint arXiv:2502.05651*.[[PDF](https://arxiv.org/pdf/2502.05651)]

Qi, Z., Kaneko, T., Takamizo, K., Ukiyo, M., & Inaba, M. (2025). KokoroChat: A Japanese Psychological Counseling Dialogue Dataset Collected via Role-Playing by Trained Counselors. *arXiv preprint arXiv:2506.01357*.[[PDF](https://arxiv.org/pdf/2506.01357?)]

Gao, S., Yu, K., Yang, Y., Yu, S., Shi, C., Wang, X., ... & Zhu, H. (2025). Large language model powered knowledge graph construction for mental health exploration. *Nature Communications*, *16*(1), 7526.[[PDF](https://www.nature.com/articles/s41467-025-62781-z.pdf)]

Sahu, N. K., Yadav, M., Chaturvedi, M., Gupta, S., & Lone, H. R. (2025, January). Leveraging language models for summarizing mental state examinations: A comprehensive evaluation and dataset release. In *Proceedings of the 31st International Conference on Computational Linguistics* (pp. 2658-2682).[[PDF](https://aclanthology.org/2025.coling-main.182.pdf)]

Raihan, N., Puspo, S. S. C., Farabi, S., Bucur, A. M., Ranasinghe, T., & Zampieri, M. (2024, May). Mentalhelp: A multi-task dataset for mental health in social media. In *Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)* (pp. 11196-11203).[[PDF](https://aclanthology.org/2024.lrec-main.977.pdf)]

Romero, A. M. M., Muñoz, A. M., Del Arco, F. M. P., Molina-González, M. D., Valdivia, M. T. M., Lopez, L. A. U., & Ráez, A. M. (2024, May). MentalRiskES: A new corpus for early detection of mental disorders in Spanish. In *Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)* (pp. 11204-11214).[[PDF](https://aclanthology.org/2024.lrec-main.978.pdf)]

Bi, G., Chen, Z., Liu, Z., Wang, H., Xiao, X., Xie, Y., ... & Huang, M. (2025). MAGI: Multi-Agent Guided Interview for Psychiatric Assessment. *arXiv preprint arXiv:2504.18260*.[[PDF](https://arxiv.org/pdf/2504.18260?)]

Yin, C., Li, F., Zhang, S., Wang, Z., Shao, J., Li, P., Chen, J., & Jiang, X. (2025). MDD-5k: A New Diagnostic Conversation Dataset for Mental Disorders Synthesized via Neuro-Symbolic LLM Agents. *Proceedings of the AAAI Conference on Artificial Intelligence*, *39*(24), 25715-25723. [[PDF](https://doi.org/10.1609/aaai.v39i24.34763)]

Xu, J., Wei, T., Hou, B., Orzechowski, P., Yang, S., Jin, R., ... & Shen, L. (2025, August). Mentalchat16k: A benchmark dataset for conversational mental health assistance. In *Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V. 2* (pp. 5367-5378).[[PDF](https://dl.acm.org/doi/10.1145/3711896.3737854)]

Wang, Y., Yang, I., Hassanpour, S., & Vosoughi, S. (2024). MentalManip: A dataset for fine-grained analysis of mental manipulation in conversations. *arXiv preprint arXiv:2405.16584*.[[PDF](https://arxiv.org/pdf/2405.16584?)]

Wang, X., Li, C., Chang, Y., Wang, J., & Wu, Y. (2024). Negativeprompt: Leveraging psychology for large language models enhancement via negative emotional stimuli. *arXiv preprint arXiv:2405.02814*.[[PDF](https://www.ijcai.org/proceedings/2024/0719.pdf)]

Kim, J., Ma, S.P., Chen, M.L. *et al.* Optimizing large language models for detecting symptoms of depression/anxiety in chronic diseases patient communications. *npj Digit. Med.* **8**, 580 (2025). [[PDF](https://doi.org/10.1038/s41746-025-01969-5)]

Wang, R., Milani, S., Chiu, J. C., Zhi, J., Eack, S. M., Labrum, T., ... & Chen, Z. Z. (2024). Patient-{\Psi}: Using large language models to simulate patients for training mental health professionals. arXiv preprint arXiv:2405.19660.[[PDF](https://arxiv.org/pdf/2405.19660)]

Chhikara, P., Pasupulety, U., Marshall, J., Chaurasia, D., & Kumari, S. (2023). Privacy aware question-answering system for online mental health risk assessment. *arXiv preprint arXiv:2306.05652*.[[PDF](https://arxiv.org/pdf/2306.05652)]

Hu, Y., Liu, D., Liu, B., Chen, Y., Cao, J., & Liu, Y. (2025, July). PsyAdvisor: A Plug-and-Play Strategy Advice Planner with Proactive Questioning in Psychological Conversations. In *Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)* (pp. 12205-12229).[[PDF](https://aclanthology.org/2025.acl-long.596.pdf)]

Yang, Q., Wang, Z., Chen, H., Wang, S., Pu, Y., Gao, X., ... & Huang, G. (2024). Psychogat: A novel psychological measurement paradigm through interactive fiction games with llm agents. *arXiv preprint arXiv:2402.12326*.[[PDF](https://arxiv.org/pdf/2402.12326)]

Wang, J., Wang, B., Fu, X., Sun, Y., Zhao, Y., & Qin, B. (2025). Psychological Counseling Cannot Be Achieved Overnight: Automated Psychological Counseling Through Multi-Session Conversations. *arXiv preprint arXiv:2506.06626*.[[PDF](https://arxiv.org/pdf/2506.06626)]

Han, J. E., Koh, J. S., Seo, H. T., Chang, D. S., & Sohn, K. A. (2024). PSYDIAL: Personality-based synthetic dialogue generation using large language models. *arXiv preprint arXiv:2404.00930*.[[PDF](https://arxiv.org/pdf/2404.00930)]

Qiu, H., & Lan, Z. (2025, July). PsyDial: A Large-scale Long-term Conversational Dataset for Mental Health Support. In *Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)* (pp. 21624-21655).[[PDF](https://aclanthology.org/2025.acl-long.1049.pdf)]

Qiu, H., Ma, L., & Lan, Z. (2024). PsyGUARD: An automated system for suicide detection and risk assessment in psychological counseling. *arXiv preprint arXiv:2409.20243*.[[PDF](https://arxiv.org/pdf/2409.20243)]

Sun, X., Tang, X., Ali, A. E., Li, Z., Ren, P., de Wit, J., ... & Bosch, J. A. (2024). Rethinking the alignment of psychotherapy dialogue generation with motivational interviewing strategies. *arXiv preprint arXiv:2408.06527*.[[PDF](https://arxiv.org/pdf/2408.06527?)]

Qiu, H., He, H., Zhang, S., Li, A., & Lan, Z. (2023). Smile: Single-turn to multi-turn inclusive language expansion via chatgpt for mental health support. *arXiv preprint arXiv:2305.00450*.[[PDF](https://arxiv.org/pdf/2305.00450)]

Hengle, A., Kulkarni, A., Patankar, S., Chandrasekaran, M., D'Silva, S., Jacob, J., & Gupta, R. (2024). Still not quite there! Evaluating large language models for comorbid mental health diagnosis. *arXiv preprint arXiv:2410.03908*.[[PDF](https://arxiv.org/pdf/2410.03908?)]

Ye, J., Xiang, L., Zhang, Y., & Zong, C. (2024). SweetieChat: A strategy-enhanced role-playing framework for diverse scenarios handling emotional support agent. *arXiv preprint arXiv:2412.08389*.[[PDF](https://arxiv.org/pdf/2412.08389)]

Lissak, S., Calderon, N., Shenkman, G., Ophir, Y., Fruchter, E., Klomek, A. B., & Reichart, R. (2024). The colorful future of llms: Evaluating and improving llms as emotional supporters for queer youth. *arXiv preprint arXiv:2402.11886*.[[PDF](https://arxiv.org/pdf/2402.11886)]

Mori, S., Ignat, O., Lee, A., & Mihalcea, R. (2024). Towards algorithmic fidelity: mental health representation across demographics in synthetic vs. human-generated data. *arXiv preprint arXiv:2403.16909*.[[PDF](https://arxiv.org/pdf/2403.16909)]

Xie, H., Chen, Y., Xing, X., Lin, J., & Xu, X. (2024). Psydt: Using llms to construct the digital twin of psychological counselor with personalized counseling style for psychological counseling. *arXiv preprint arXiv:2412.13660*.[[PDF](https://arxiv.org/pdf/2412.13660)]

Chen, Z., Cao, Y., Bi, G., Wu, J., Zhou, J., Xiao, X., Chen, S., Wang, H., & Huang, M. (2025). SocialSim: Towards Socialized Simulation of Emotional Support Conversation. *Proceedings of the AAAI Conference on Artificial Intelligence*, *39*(2), 1274-1282. [[PDF](https://ojs.aaai.org/index.php/AAAI/article/view/32116)]

Wang, J., Huang, Y., Liu, Z., Xu, D., Wang, C., Shi, X., Guan, R., Wang, H., Yue, W., & Huang, Y. (2025). STAMPsy: Towards SpatioTemporal-Aware Mixed-Type Dialogues for Psychological Counseling. *Proceedings of the AAAI Conference on Artificial Intelligence*, *39*(24), 25371-25379. [[PDF](https://doi.org/10.1609/aaai.v39i24.34725)]

Lissak, S., Calderon, N., Shenkman, G., Ophir, Y., Fruchter, E., Klomek, A. B., & Reichart, R. (2024). The colorful future of llms: Evaluating and improving llms as emotional supporters for queer youth. *arXiv preprint arXiv:2402.11886*.[[PDF](https://arxiv.org/pdf/2402.11886)]

Xu, B., Li, L., Wang, J., Qiao, X., Yu, E., Qian, Y., ... & Lin, H. Unveiling Maternity and Infant Care Conversations: A Chinese Dialogue Dataset for Enhanced Parenting Support.[[PDF](https://www.ijcai.org/proceedings/2025/0923.pdf)]

Shinoda, K., Hojo, N., Nishida, K., Mizuno, S., Suzuki, K., Masumura, R., Sugiyama, H., & Saito, K. (2025). ToMATO: Verbalizing the Mental States of Role-Playing LLMs for Benchmarking Theory of Mind. *Proceedings of the AAAI Conference on Artificial Intelligence*, *39*(2), 1520-1528. [[PDF](https://doi.org/10.1609/aaai.v39i2.32143)]

Yang, K., Ji, S., Zhang, T., Xie, Q., Kuang, Z., & Ananiadou, S. (2023). Towards interpretable mental health analysis with large language models. *arXiv preprint arXiv:2304.03347*.[[PDF](https://arxiv.org/pdf/2304.03347)]

Balan, R., Dobrean, A., & Poetar, C. R. (2024). Use of automated conversational agents in improving young population mental health: a scoping review. *NPJ Digital Medicine*, *7*(1), 75.[[PDF](https://www.nature.com/articles/s41746-024-01072-1.pdf)]

Meng, H., Chen, Y., Li, Y., Yang, Y., Lee, J., Zhang, R., & Lee, Y. C. (2025). What is Stigma Attributed to? A Theory-Grounded, Expert-Annotated Interview Corpus for Demystifying Mental-Health Stigma. *arXiv preprint arXiv:2505.12727*.[[PDF](https://arxiv.org/pdf/2505.12727)]

Shu, B., Zhang, L., Choi, M., Dunagan, L., Logeswaran, L., Lee, M., ... & Jurgens, D. (2023). You don't need a personality test to know these models are unreliable: Assessing the Reliability of Large Language Models on Psychometric Instruments. *arXiv preprint arXiv:2311.09718*.[[PDF](https://arxiv.org/pdf/2311.09718)]

## Clinical application

Mishra, K., Priya, P., & Ekbal, A. (2023). Help Me Heal: A Reinforced Polite and Empathetic Mental Health and Legal Counseling Dialogue System for Crime Victims. *Proceedings of the AAAI Conference on Artificial Intelligence*, *37*(12), 14408-14416.[[PDF](https://doi.org/10.1609/aaai.v37i12.26685)]

Kim, J., Leonte, K. G., Chen, M. L., Torous, J. B., Linos, E., Pinto, A., & Rodriguez, C. I. (2024). Large language models outperform mental and medical health care professionals in identifying obsessive-compulsive disorder. *NPJ Digital Medicine*, *7*(1), 193.[[PDF](https://www.nature.com/articles/s41746-024-01181-x.pdf)]

Siddals, S., Torous, J., & Coxon, A. (2024). “It happened to be the perfect thing”: experiences of generative AI chatbots for mental health. *npj Mental Health Research*, *3*(1), 48.[[PDF](https://www.nature.com/articles/s44184-024-00097-4.pdf)]

Hur, J. K., Heffner, J., Feng, G. W., Joormann, J., & Rutledge, R. B. (2024). Language sentiment predicts changes in depressive symptoms. *Proceedings of the National Academy of Sciences*, *121*(39), e2321321121.[[PDF](https://www.pnas.org/doi/pdf/10.1073/pnas.2321321121)]

Maples, B., Cerit, M., Vishwanath, A., & Pea, R. (2024). Loneliness and suicide mitigation for students using GPT3-enabled chatbots. *npj mental health research*, *3*(1), 4.[[PDF](https://www.nature.com/articles/s44184-023-00047-6.pdf)]

Priya, P., Mishra, K., Totala, P., & Ekbal, A. (2023, August). PARTNER: A Persuasive Mental Health and Legal Counselling Dialogue System for Women and Children Crime Victims. In *IJCAI* (pp. 6183-6191).[[PDF](https://www.ijcai.org/proceedings/2023/686)]

Gollapalli, S. D., & Ng, S. K. (2025, January). PIRsuader: A persuasive chatbot for mitigating psychological insulin resistance in type-2 diabetic patients. In *Proceedings of the 31st International Conference on Computational Linguistics* (pp. 5997-6013).[[PDF](https://aclanthology.org/2025.coling-main.401.pdf)]

Chen, C. H., Wu, C. S., Su, C. H., & Chen, H. H. TimelyMed: AI-Driven Clinical Course Attribution and Temporal Mapping for Psychiatric Medical Records.[[PDF](https://www.ijcai.org/proceedings/2025/1252.pdf)]





